{"cells":[{"cell_type":"code","source":[" from pyspark.sql.functions import *"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2aa7af26-d2ce-4aad-bad6-225c6415217c","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["d1=[[\"1\",\"11-01-2020\",\"2020-07-01\",\"2020-07-01 12:01:19.111\"],[\"2\",\"21-05-2019\",\"2019-01-11\",\"2019-06-24 12:01:19.222\"],[\"3\",\"19-11-2021\",\"2021-12-07\",\"2021-11-16 16:44:55.406\"]]\ndf=spark.createDataFrame(d1,[\"id\",\"sample_date\",\"sample_date1\",\"sample_timestamp\"])\ndf.show(truncate=False)\ndf.printSchema()\n  "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"80de2cf9-7cd3-478f-90a1-3914b6fe7653","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---+-----------+------------+-----------------------+\n|id |sample_date|sample_date1|sample_timestamp       |\n+---+-----------+------------+-----------------------+\n|1  |11-01-2020 |2020-07-01  |2020-07-01 12:01:19.111|\n|2  |21-05-2019 |2019-01-11  |2019-06-24 12:01:19.222|\n|3  |19-11-2021 |2021-12-07  |2021-11-16 16:44:55.406|\n+---+-----------+------------+-----------------------+\n\nroot\n |-- id: string (nullable = true)\n |-- sample_date: string (nullable = true)\n |-- sample_date1: string (nullable = true)\n |-- sample_timestamp: string (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+-----------+------------+-----------------------+\n|id |sample_date|sample_date1|sample_timestamp       |\n+---+-----------+------------+-----------------------+\n|1  |11-01-2020 |2020-07-01  |2020-07-01 12:01:19.111|\n|2  |21-05-2019 |2019-01-11  |2019-06-24 12:01:19.222|\n|3  |19-11-2021 |2021-12-07  |2021-11-16 16:44:55.406|\n+---+-----------+------------+-----------------------+\n\nroot\n |-- id: string (nullable = true)\n |-- sample_date: string (nullable = true)\n |-- sample_date1: string (nullable = true)\n |-- sample_timestamp: string (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["'''\nDefault date format expected is yyyy-MM-dd  i.e 2020-01-11\nIf the date or timestamp is not in that format, need to specify the format explicitly.\n'''\n\ndf=df.withColumn(\"sample_date\",to_date(\"sample_date\",format = 'dd-MM-yyyy')) \\\n      .withColumn(\"sample_date1\",to_date(\"sample_date1\")) \\\n      .withColumn(\"sample_timestamp\",to_timestamp(\"sample_timestamp\"))\n\ndf.show(truncate=False)\ndf.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"1a5a931c-5069-495f-ad75-fb194f47024d","inputWidgets":{},"title":"String to date and timestamp"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---+-----------+------------+-----------------------+\n|id |sample_date|sample_date1|sample_timestamp       |\n+---+-----------+------------+-----------------------+\n|1  |2020-01-11 |2020-07-01  |2020-07-01 12:01:19.111|\n|2  |2019-05-21 |2019-01-11  |2019-06-24 12:01:19.222|\n|3  |2021-11-19 |2021-12-07  |2021-11-16 16:44:55.406|\n+---+-----------+------------+-----------------------+\n\nroot\n |-- id: string (nullable = true)\n |-- sample_date: date (nullable = true)\n |-- sample_date1: date (nullable = true)\n |-- sample_timestamp: timestamp (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+-----------+------------+-----------------------+\n|id |sample_date|sample_date1|sample_timestamp       |\n+---+-----------+------------+-----------------------+\n|1  |2020-01-11 |2020-07-01  |2020-07-01 12:01:19.111|\n|2  |2019-05-21 |2019-01-11  |2019-06-24 12:01:19.222|\n|3  |2021-11-19 |2021-12-07  |2021-11-16 16:44:55.406|\n+---+-----------+------------+-----------------------+\n\nroot\n |-- id: string (nullable = true)\n |-- sample_date: date (nullable = true)\n |-- sample_date1: date (nullable = true)\n |-- sample_timestamp: timestamp (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["'''\nCreati temporary view to check sql queries\n'''\n\ndf.createOrReplaceTempView(\"date_testing\")\nspark.sql(\"select * from date_testing;\").show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9ab65244-d4fd-44b0-8c61-993063b448db","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---+-----------+------------+-----------------------+\n|id |sample_date|sample_date1|sample_timestamp       |\n+---+-----------+------------+-----------------------+\n|1  |2020-01-11 |2020-07-01  |2020-07-01 12:01:19.111|\n|2  |2019-05-21 |2019-01-11  |2019-06-24 12:01:19.222|\n|3  |2021-11-19 |2021-12-07  |2021-11-16 16:44:55.406|\n+---+-----------+------------+-----------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+-----------+------------+-----------------------+\n|id |sample_date|sample_date1|sample_timestamp       |\n+---+-----------+------------+-----------------------+\n|1  |2020-01-11 |2020-07-01  |2020-07-01 12:01:19.111|\n|2  |2019-05-21 |2019-01-11  |2019-06-24 12:01:19.222|\n|3  |2021-11-19 |2021-12-07  |2021-11-16 16:44:55.406|\n+---+-----------+------------+-----------------------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Date transformations"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"511a0dc7-89db-48a0-a00c-dc83c6fcf76d","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["'''\nGet the date in any format required using date_format\n''' \nprint(\"Using Pyhton \\n\",\"*\"*20)\ndf2=df.select(\"sample_date\").withColumn(\"formatted_date\",date_format(\"sample_date\",\"MM/dd/yyyy\"))\ndf2.show()\ndf2.printSchema()\n\nprint(\"Using SQL \\n\",\"*\"*20)\ndf2=spark.sql(\"select sample_date,date_format(sample_date,'MM/dd/yyyy') as formatted_date from date_testing;\")\ndf2.show()\ndf2.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e97e47f4-3d21-4583-b819-b082558cbc3f","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Using Pyhton \n ********************\n+-----------+--------------+\n|sample_date|formatted_date|\n+-----------+--------------+\n| 2020-01-11|    01/11/2020|\n| 2019-05-21|    05/21/2019|\n| 2021-11-19|    11/19/2021|\n+-----------+--------------+\n\nroot\n |-- sample_date: date (nullable = true)\n |-- formatted_date: string (nullable = true)\n\nUsing SQL \n ********************\n+-----------+--------------+\n|sample_date|formatted_date|\n+-----------+--------------+\n| 2020-01-11|    01/11/2020|\n| 2019-05-21|    05/21/2019|\n| 2021-11-19|    11/19/2021|\n+-----------+--------------+\n\nroot\n |-- sample_date: date (nullable = true)\n |-- formatted_date: string (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Using Pyhton \n ********************\n+-----------+--------------+\n|sample_date|formatted_date|\n+-----------+--------------+\n| 2020-01-11|    01/11/2020|\n| 2019-05-21|    05/21/2019|\n| 2021-11-19|    11/19/2021|\n+-----------+--------------+\n\nroot\n |-- sample_date: date (nullable = true)\n |-- formatted_date: string (nullable = true)\n\nUsing SQL \n ********************\n+-----------+--------------+\n|sample_date|formatted_date|\n+-----------+--------------+\n| 2020-01-11|    01/11/2020|\n| 2019-05-21|    05/21/2019|\n| 2021-11-19|    11/19/2021|\n+-----------+--------------+\n\nroot\n |-- sample_date: date (nullable = true)\n |-- formatted_date: string (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["'''\nTimestamp to date\n''' \nprint(\"Using Pyhton \\n\",\"*\"*20)\ndf2=df.select(\"sample_timestamp\").withColumn(\"date\",to_date(\"sample_timestamp\")) \\\n                                 .withColumn(\"formatted_date\",date_format(\"sample_timestamp\",format=\"dd-MM-yyyy\"))\ndf2.show(truncate=False)\ndf2.printSchema()\n\nprint(\"Using SQL \\n\",\"*\"*20)\ndf2=spark.sql(\"\"\"select sample_timestamp,\n                        to_date(sample_timestamp) as date, \n                        date_format(sample_timestamp,'dd-MM-yyyy') as formatted_date \n                 from date_testing;\"\"\")\ndf2.show(truncate=False)\ndf2.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"95930667-3ad4-4fa8-ad0f-e4636c0b154d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Using Pyhton \n ********************\n+-----------------------+----------+--------------+\n|sample_timestamp       |date      |formatted_date|\n+-----------------------+----------+--------------+\n|2020-07-01 12:01:19.111|2020-07-01|01-07-2020    |\n|2019-06-24 12:01:19.222|2019-06-24|24-06-2019    |\n|2021-11-16 16:44:55.406|2021-11-16|16-11-2021    |\n+-----------------------+----------+--------------+\n\nroot\n |-- sample_timestamp: timestamp (nullable = true)\n |-- date: date (nullable = true)\n |-- formatted_date: string (nullable = true)\n\nUsing SQL \n ********************\n+-----------------------+----------+--------------+\n|sample_timestamp       |date      |formatted_date|\n+-----------------------+----------+--------------+\n|2020-07-01 12:01:19.111|2020-07-01|01-07-2020    |\n|2019-06-24 12:01:19.222|2019-06-24|24-06-2019    |\n|2021-11-16 16:44:55.406|2021-11-16|16-11-2021    |\n+-----------------------+----------+--------------+\n\nroot\n |-- sample_timestamp: timestamp (nullable = true)\n |-- date: date (nullable = true)\n |-- formatted_date: string (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Using Pyhton \n ********************\n+-----------------------+----------+--------------+\n|sample_timestamp       |date      |formatted_date|\n+-----------------------+----------+--------------+\n|2020-07-01 12:01:19.111|2020-07-01|01-07-2020    |\n|2019-06-24 12:01:19.222|2019-06-24|24-06-2019    |\n|2021-11-16 16:44:55.406|2021-11-16|16-11-2021    |\n+-----------------------+----------+--------------+\n\nroot\n |-- sample_timestamp: timestamp (nullable = true)\n |-- date: date (nullable = true)\n |-- formatted_date: string (nullable = true)\n\nUsing SQL \n ********************\n+-----------------------+----------+--------------+\n|sample_timestamp       |date      |formatted_date|\n+-----------------------+----------+--------------+\n|2020-07-01 12:01:19.111|2020-07-01|01-07-2020    |\n|2019-06-24 12:01:19.222|2019-06-24|24-06-2019    |\n|2021-11-16 16:44:55.406|2021-11-16|16-11-2021    |\n+-----------------------+----------+--------------+\n\nroot\n |-- sample_timestamp: timestamp (nullable = true)\n |-- date: date (nullable = true)\n |-- formatted_date: string (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["'''\nAdd interval to dates\n''' \nprint(\"Using Pyhton \\n\",\"*\"*20)\ndf2=df.select('sample_date',\n              expr('sample_date + INTERVAL 10 DAYS').alias(\"add_date1\"),\n              date_add(\"sample_date\",10).alias(\"add_date2\"),\n              expr('sample_date + INTERVAL 2 MONTHS as add_months'),\n             )\ndf2.show(truncate=False)\ndf2.printSchema()\n\nprint(\"Using SQL \\n\",\"*\"*20)\ndf2=spark.sql(\"\"\"select sample_date,\n                        sample_date + INTERVAL 10 DAYS as add_date1,\n                        date_add(sample_date,10) as add_date2,\n                        sample_date + INTERVAL 10 MONTHS as add_months\n                 from date_testing;\"\"\")\ndf2.show(truncate=False)\ndf2.printSchema()\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"64a4e3d8-762c-476f-92d4-1f710b3c11a1","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Using Pyhton \n ********************\n+-----------+----------+----------+----------+\n|sample_date|add_date1 |add_date2 |add_months|\n+-----------+----------+----------+----------+\n|2020-01-11 |2020-01-21|2020-01-21|2020-03-11|\n|2019-05-21 |2019-05-31|2019-05-31|2019-07-21|\n|2021-11-19 |2021-11-29|2021-11-29|2022-01-19|\n+-----------+----------+----------+----------+\n\nroot\n |-- sample_date: date (nullable = true)\n |-- add_date1: date (nullable = true)\n |-- add_date2: date (nullable = true)\n |-- add_months: date (nullable = true)\n\nUsing SQL \n ********************\n+-----------+----------+----------+----------+\n|sample_date|add_date1 |add_date2 |add_months|\n+-----------+----------+----------+----------+\n|2020-01-11 |2020-01-21|2020-01-21|2020-11-11|\n|2019-05-21 |2019-05-31|2019-05-31|2020-03-21|\n|2021-11-19 |2021-11-29|2021-11-29|2022-09-19|\n+-----------+----------+----------+----------+\n\nroot\n |-- sample_date: date (nullable = true)\n |-- add_date1: date (nullable = true)\n |-- add_date2: date (nullable = true)\n |-- add_months: date (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Using Pyhton \n ********************\n+-----------+----------+----------+----------+\n|sample_date|add_date1 |add_date2 |add_months|\n+-----------+----------+----------+----------+\n|2020-01-11 |2020-01-21|2020-01-21|2020-03-11|\n|2019-05-21 |2019-05-31|2019-05-31|2019-07-21|\n|2021-11-19 |2021-11-29|2021-11-29|2022-01-19|\n+-----------+----------+----------+----------+\n\nroot\n |-- sample_date: date (nullable = true)\n |-- add_date1: date (nullable = true)\n |-- add_date2: date (nullable = true)\n |-- add_months: date (nullable = true)\n\nUsing SQL \n ********************\n+-----------+----------+----------+----------+\n|sample_date|add_date1 |add_date2 |add_months|\n+-----------+----------+----------+----------+\n|2020-01-11 |2020-01-21|2020-01-21|2020-11-11|\n|2019-05-21 |2019-05-31|2019-05-31|2020-03-21|\n|2021-11-19 |2021-11-29|2021-11-29|2022-09-19|\n+-----------+----------+----------+----------+\n\nroot\n |-- sample_date: date (nullable = true)\n |-- add_date1: date (nullable = true)\n |-- add_date2: date (nullable = true)\n |-- add_months: date (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["'''\nFetch YEAR, MONTH, DAY...\nSUNDAY - 0 , SATURDAY - 7\n''' \nprint(\"Using Pyhton \\n\",\"*\"*20)\ndf2=df.select('sample_date',\n              year(\"sample_date\").alias(\"year\"),\n              month(\"sample_date\").alias(\"month\"),\n              dayofmonth(\"sample_date\").alias(\"day\"),              \n              dayofweek(\"sample_date\").alias(\"day of week\"),\n              weekofyear(\"sample_date\").alias(\"weak of year\"),\n              quarter(\"sample_date\").alias(\"quarter\"),\n              next_day(\"sample_date\",\"Friday\").alias(\"Date of upcoming Friday\"),\n             )\ndf2.show(truncate=False)\ndf2.printSchema()\n\nprint(\"Using SQL \\n\",\"*\"*20)\ndf2=spark.sql(\"\"\"select sample_date,\n                        year(sample_date) as date_year,\n                        month(sample_date) as month,\n                        dayofmonth(sample_date) as day,\n                        dayofweek(sample_date) as day_of_week,\n                        weekofyear(sample_date) as week_of_year,\n                        quarter(sample_date) as quarter,\n                        next_day(sample_date,'Friday') as date_of_upcoming_Friday\n                 from date_testing;\"\"\")\ndf2.show(truncate=False)\ndf2.printSchema()\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5de695e5-c978-4bc4-ab4a-8ee9f6a3ae57","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Using Pyhton \n ********************\n+-----------+----+-----+---+-----------+------------+-------+-----------------------+\n|sample_date|year|month|day|day of week|weak of year|quarter|Date of upcoming Friday|\n+-----------+----+-----+---+-----------+------------+-------+-----------------------+\n|2020-01-11 |2020|1    |11 |7          |2           |1      |2020-01-17             |\n|2019-05-21 |2019|5    |21 |3          |21          |2      |2019-05-24             |\n|2021-11-19 |2021|11   |19 |6          |46          |4      |2021-11-26             |\n+-----------+----+-----+---+-----------+------------+-------+-----------------------+\n\nroot\n |-- sample_date: date (nullable = true)\n |-- year: integer (nullable = true)\n |-- month: integer (nullable = true)\n |-- day: integer (nullable = true)\n |-- day of week: integer (nullable = true)\n |-- weak of year: integer (nullable = true)\n |-- quarter: integer (nullable = true)\n |-- Date of upcoming Friday: date (nullable = true)\n\nUsing SQL \n ********************\n+-----------+---------+-----+---+-----------+------------+-------+-----------------------+\n|sample_date|date_year|month|day|day_of_week|week_of_year|quarter|date_of_upcoming_Friday|\n+-----------+---------+-----+---+-----------+------------+-------+-----------------------+\n|2020-01-11 |2020     |1    |11 |7          |2           |1      |2020-01-17             |\n|2019-05-21 |2019     |5    |21 |3          |21          |2      |2019-05-24             |\n|2021-11-19 |2021     |11   |19 |6          |46          |4      |2021-11-26             |\n+-----------+---------+-----+---+-----------+------------+-------+-----------------------+\n\nroot\n |-- sample_date: date (nullable = true)\n |-- date_year: integer (nullable = true)\n |-- month: integer (nullable = true)\n |-- day: integer (nullable = true)\n |-- day_of_week: integer (nullable = true)\n |-- week_of_year: integer (nullable = true)\n |-- quarter: integer (nullable = true)\n |-- date_of_upcoming_Friday: date (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Using Pyhton \n ********************\n+-----------+----+-----+---+-----------+------------+-------+-----------------------+\n|sample_date|year|month|day|day of week|weak of year|quarter|Date of upcoming Friday|\n+-----------+----+-----+---+-----------+------------+-------+-----------------------+\n|2020-01-11 |2020|1    |11 |7          |2           |1      |2020-01-17             |\n|2019-05-21 |2019|5    |21 |3          |21          |2      |2019-05-24             |\n|2021-11-19 |2021|11   |19 |6          |46          |4      |2021-11-26             |\n+-----------+----+-----+---+-----------+------------+-------+-----------------------+\n\nroot\n |-- sample_date: date (nullable = true)\n |-- year: integer (nullable = true)\n |-- month: integer (nullable = true)\n |-- day: integer (nullable = true)\n |-- day of week: integer (nullable = true)\n |-- weak of year: integer (nullable = true)\n |-- quarter: integer (nullable = true)\n |-- Date of upcoming Friday: date (nullable = true)\n\nUsing SQL \n ********************\n+-----------+---------+-----+---+-----------+------------+-------+-----------------------+\n|sample_date|date_year|month|day|day_of_week|week_of_year|quarter|date_of_upcoming_Friday|\n+-----------+---------+-----+---+-----------+------------+-------+-----------------------+\n|2020-01-11 |2020     |1    |11 |7          |2           |1      |2020-01-17             |\n|2019-05-21 |2019     |5    |21 |3          |21          |2      |2019-05-24             |\n|2021-11-19 |2021     |11   |19 |6          |46          |4      |2021-11-26             |\n+-----------+---------+-----+---+-----------+------------+-------+-----------------------+\n\nroot\n |-- sample_date: date (nullable = true)\n |-- date_year: integer (nullable = true)\n |-- month: integer (nullable = true)\n |-- day: integer (nullable = true)\n |-- day_of_week: integer (nullable = true)\n |-- week_of_year: integer (nullable = true)\n |-- quarter: integer (nullable = true)\n |-- date_of_upcoming_Friday: date (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["'''\nDates diff and add\n''' \nprint(\"Using Pyhton \\n\",\"*\"*20)\ndf2=df.select('sample_date',\n              datediff(current_date(),\"sample_date\").alias(\"date_diff_in_days\"),\n              months_between(current_date(),\"sample_date\").alias(\"months_between\"),\n              date_add(\"sample_date\",5).alias(\"date+5\"),\n              date_add(\"sample_date\",-5).alias(\"date-5\"),\n              date_sub(\"sample_date\",-5).alias(\"date+5_1\"),\n              date_sub(\"sample_date\",5).alias(\"date-5_1\"),\n              add_months(\"sample_date\",20).alias(\"add_months\"),\n              add_months(\"sample_date\",-40).alias(\"subtract_months\"), \n              \n              # set to the first of that month or year\n              trunc(\"sample_date\",\"Month\").alias(\"truncate_month\"),\n              trunc(\"sample_date\",\"Year\").alias(\"truncate_year\")\n             )\ndf2.show(truncate=False)\ndf2.printSchema()\n\nprint(\"Using SQL \\n\",\"*\"*20)\ndf2=spark.sql(\"\"\"select sample_date,\n                        datediff(current_date(),sample_date) as date_diff_in_days,\n                        months_between(current_date(),sample_date) as months_between,\n                        date_add(sample_date,5) as date_add_5,\n                        date_add(sample_date,-5) as date_sub_5,\n                        date_sub(sample_date,-5) as date_add_5_1,\n                        date_sub(sample_date,5) as date_sub_5_1,\n                        add_months(sample_date,20) as add_months,\n                        add_months(sample_date,-40) as subtract_months, \n                        --set to the first of that month or year\n                        trunc(sample_date,'Month') as truncate_month,\n                        trunc(sample_date,'Year') as truncate_year\n                 from date_testing;\"\"\")\ndf2.show(truncate=False)\ndf2.printSchema()\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d10389a5-c36f-4b0b-a3c3-3192fb9538f7","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Using Pyhton \n ********************\n+-----------+-----------------+--------------+----------+----------+----------+----------+----------+---------------+--------------+-------------+\n|sample_date|date_diff_in_days|months_between|date+5    |date-5    |date+5_1  |date-5_1  |add_months|subtract_months|truncate_month|truncate_year|\n+-----------+-----------------+--------------+----------+----------+----------+----------+----------+---------------+--------------+-------------+\n|2020-01-11 |1059             |34.80645161   |2020-01-16|2020-01-06|2020-01-16|2020-01-06|2021-09-11|2016-09-11     |2020-01-01    |2020-01-01   |\n|2019-05-21 |1294             |42.48387097   |2019-05-26|2019-05-16|2019-05-26|2019-05-16|2021-01-21|2016-01-21     |2019-05-01    |2019-01-01   |\n|2021-11-19 |381              |12.5483871    |2021-11-24|2021-11-14|2021-11-24|2021-11-14|2023-07-19|2018-07-19     |2021-11-01    |2021-01-01   |\n+-----------+-----------------+--------------+----------+----------+----------+----------+----------+---------------+--------------+-------------+\n\nroot\n |-- sample_date: date (nullable = true)\n |-- date_diff_in_days: integer (nullable = true)\n |-- months_between: double (nullable = true)\n |-- date+5: date (nullable = true)\n |-- date-5: date (nullable = true)\n |-- date+5_1: date (nullable = true)\n |-- date-5_1: date (nullable = true)\n |-- add_months: date (nullable = true)\n |-- subtract_months: date (nullable = true)\n |-- truncate_month: date (nullable = true)\n |-- truncate_year: date (nullable = true)\n\nUsing SQL \n ********************\n+-----------+-----------------+--------------+----------+----------+------------+------------+----------+---------------+--------------+-------------+\n|sample_date|date_diff_in_days|months_between|date_add_5|date_sub_5|date_add_5_1|date_sub_5_1|add_months|subtract_months|truncate_month|truncate_year|\n+-----------+-----------------+--------------+----------+----------+------------+------------+----------+---------------+--------------+-------------+\n|2020-01-11 |1059             |34.80645161   |2020-01-16|2020-01-06|2020-01-16  |2020-01-06  |2021-09-11|2016-09-11     |2020-01-01    |2020-01-01   |\n|2019-05-21 |1294             |42.48387097   |2019-05-26|2019-05-16|2019-05-26  |2019-05-16  |2021-01-21|2016-01-21     |2019-05-01    |2019-01-01   |\n|2021-11-19 |381              |12.5483871    |2021-11-24|2021-11-14|2021-11-24  |2021-11-14  |2023-07-19|2018-07-19     |2021-11-01    |2021-01-01   |\n+-----------+-----------------+--------------+----------+----------+------------+------------+----------+---------------+--------------+-------------+\n\nroot\n |-- sample_date: date (nullable = true)\n |-- date_diff_in_days: integer (nullable = true)\n |-- months_between: double (nullable = true)\n |-- date_add_5: date (nullable = true)\n |-- date_sub_5: date (nullable = true)\n |-- date_add_5_1: date (nullable = true)\n |-- date_sub_5_1: date (nullable = true)\n |-- add_months: date (nullable = true)\n |-- subtract_months: date (nullable = true)\n |-- truncate_month: date (nullable = true)\n |-- truncate_year: date (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Using Pyhton \n ********************\n+-----------+-----------------+--------------+----------+----------+----------+----------+----------+---------------+--------------+-------------+\n|sample_date|date_diff_in_days|months_between|date+5    |date-5    |date+5_1  |date-5_1  |add_months|subtract_months|truncate_month|truncate_year|\n+-----------+-----------------+--------------+----------+----------+----------+----------+----------+---------------+--------------+-------------+\n|2020-01-11 |1059             |34.80645161   |2020-01-16|2020-01-06|2020-01-16|2020-01-06|2021-09-11|2016-09-11     |2020-01-01    |2020-01-01   |\n|2019-05-21 |1294             |42.48387097   |2019-05-26|2019-05-16|2019-05-26|2019-05-16|2021-01-21|2016-01-21     |2019-05-01    |2019-01-01   |\n|2021-11-19 |381              |12.5483871    |2021-11-24|2021-11-14|2021-11-24|2021-11-14|2023-07-19|2018-07-19     |2021-11-01    |2021-01-01   |\n+-----------+-----------------+--------------+----------+----------+----------+----------+----------+---------------+--------------+-------------+\n\nroot\n |-- sample_date: date (nullable = true)\n |-- date_diff_in_days: integer (nullable = true)\n |-- months_between: double (nullable = true)\n |-- date+5: date (nullable = true)\n |-- date-5: date (nullable = true)\n |-- date+5_1: date (nullable = true)\n |-- date-5_1: date (nullable = true)\n |-- add_months: date (nullable = true)\n |-- subtract_months: date (nullable = true)\n |-- truncate_month: date (nullable = true)\n |-- truncate_year: date (nullable = true)\n\nUsing SQL \n ********************\n+-----------+-----------------+--------------+----------+----------+------------+------------+----------+---------------+--------------+-------------+\n|sample_date|date_diff_in_days|months_between|date_add_5|date_sub_5|date_add_5_1|date_sub_5_1|add_months|subtract_months|truncate_month|truncate_year|\n+-----------+-----------------+--------------+----------+----------+------------+------------+----------+---------------+--------------+-------------+\n|2020-01-11 |1059             |34.80645161   |2020-01-16|2020-01-06|2020-01-16  |2020-01-06  |2021-09-11|2016-09-11     |2020-01-01    |2020-01-01   |\n|2019-05-21 |1294             |42.48387097   |2019-05-26|2019-05-16|2019-05-26  |2019-05-16  |2021-01-21|2016-01-21     |2019-05-01    |2019-01-01   |\n|2021-11-19 |381              |12.5483871    |2021-11-24|2021-11-14|2021-11-24  |2021-11-14  |2023-07-19|2018-07-19     |2021-11-01    |2021-01-01   |\n+-----------+-----------------+--------------+----------+----------+------------+------------+----------+---------------+--------------+-------------+\n\nroot\n |-- sample_date: date (nullable = true)\n |-- date_diff_in_days: integer (nullable = true)\n |-- months_between: double (nullable = true)\n |-- date_add_5: date (nullable = true)\n |-- date_sub_5: date (nullable = true)\n |-- date_add_5_1: date (nullable = true)\n |-- date_sub_5_1: date (nullable = true)\n |-- add_months: date (nullable = true)\n |-- subtract_months: date (nullable = true)\n |-- truncate_month: date (nullable = true)\n |-- truncate_year: date (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Timestamp  transformations"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"ab92e79d-8e23-4c5b-9153-df12d7c9cb79","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["'''\nAdd interval to Timestamps\n''' \nprint(\"Using Pyhton \\n\",\"*\"*20)\ndf2=df.select('sample_timestamp',\n              to_date('sample_timestamp').alias('timestamp_to_date'),\n              expr('sample_timestamp + INTERVAL 10 SECONDS').alias(\"add_timestamp1\"),\n              date_add(\"sample_timestamp\",10).alias(\"add_timestamp2\"),\n              expr('sample_timestamp + INTERVAL 2 MONTHS as add_months'),\n              # converting to unix_timestamp and subtracting\n              ((current_timestamp().cast(\"long\")-col('sample_timestamp').cast(\"long\"))/60).alias(\"timestamp_diff_in_days\")\n             )\ndf2.show(truncate=False)\ndf2.printSchema()\n\nprint(\"Using SQL \\n\",\"*\"*20)\ndf2=spark.sql(\"\"\"select sample_timestamp,\n                        to_date(sample_timestamp) as timestamp_to_date,\n                        sample_timestamp + INTERVAL 10 SECONDS as add_timestamp1,\n                        date_add(sample_timestamp,10) as add_timestamp2,\n                        sample_timestamp + INTERVAL 10 MONTHS as add_months,\n                        (cast(current_timestamp() as int)-cast(sample_timestamp as int))/60 as timestamp_diff_in_days\n                 from date_testing;\"\"\")\ndf2.show(truncate=False)\ndf2.printSchema()\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"9d6c193e-ced7-4fd0-804f-25fe7710f8d6","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Using Pyhton \n ********************\n+-----------------------+-----------------+-----------------------+--------------+-----------------------+----------------------+\n|sample_timestamp       |timestamp_to_date|add_timestamp1         |add_timestamp2|add_months             |timestamp_diff_in_days|\n+-----------------------+-----------------+-----------------------+--------------+-----------------------+----------------------+\n|2020-07-01 12:01:19.111|2020-07-01       |2020-07-01 12:01:29.111|2020-07-11    |2020-09-01 12:01:19.111|1277445.4833333334    |\n|2019-06-24 12:01:19.222|2019-06-24       |2019-06-24 12:01:29.222|2019-07-04    |2019-08-24 12:01:19.222|1814565.4833333334    |\n|2021-11-16 16:44:55.406|2021-11-16       |2021-11-16 16:45:05.406|2021-11-26    |2022-01-16 16:44:55.406|552841.8833333333     |\n+-----------------------+-----------------+-----------------------+--------------+-----------------------+----------------------+\n\nroot\n |-- sample_timestamp: timestamp (nullable = true)\n |-- timestamp_to_date: date (nullable = true)\n |-- add_timestamp1: timestamp (nullable = true)\n |-- add_timestamp2: date (nullable = true)\n |-- add_months: timestamp (nullable = true)\n |-- timestamp_diff_in_days: double (nullable = true)\n\nUsing SQL \n ********************\n+-----------------------+-----------------+-----------------------+--------------+-----------------------+----------------------+\n|sample_timestamp       |timestamp_to_date|add_timestamp1         |add_timestamp2|add_months             |timestamp_diff_in_days|\n+-----------------------+-----------------+-----------------------+--------------+-----------------------+----------------------+\n|2020-07-01 12:01:19.111|2020-07-01       |2020-07-01 12:01:29.111|2020-07-11    |2021-05-01 12:01:19.111|1277445.4833333334    |\n|2019-06-24 12:01:19.222|2019-06-24       |2019-06-24 12:01:29.222|2019-07-04    |2020-04-24 12:01:19.222|1814565.4833333334    |\n|2021-11-16 16:44:55.406|2021-11-16       |2021-11-16 16:45:05.406|2021-11-26    |2022-09-16 16:44:55.406|552841.8833333333     |\n+-----------------------+-----------------+-----------------------+--------------+-----------------------+----------------------+\n\nroot\n |-- sample_timestamp: timestamp (nullable = true)\n |-- timestamp_to_date: date (nullable = true)\n |-- add_timestamp1: timestamp (nullable = true)\n |-- add_timestamp2: date (nullable = true)\n |-- add_months: timestamp (nullable = true)\n |-- timestamp_diff_in_days: double (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Using Pyhton \n ********************\n+-----------------------+-----------------+-----------------------+--------------+-----------------------+----------------------+\n|sample_timestamp       |timestamp_to_date|add_timestamp1         |add_timestamp2|add_months             |timestamp_diff_in_days|\n+-----------------------+-----------------+-----------------------+--------------+-----------------------+----------------------+\n|2020-07-01 12:01:19.111|2020-07-01       |2020-07-01 12:01:29.111|2020-07-11    |2020-09-01 12:01:19.111|1277445.4833333334    |\n|2019-06-24 12:01:19.222|2019-06-24       |2019-06-24 12:01:29.222|2019-07-04    |2019-08-24 12:01:19.222|1814565.4833333334    |\n|2021-11-16 16:44:55.406|2021-11-16       |2021-11-16 16:45:05.406|2021-11-26    |2022-01-16 16:44:55.406|552841.8833333333     |\n+-----------------------+-----------------+-----------------------+--------------+-----------------------+----------------------+\n\nroot\n |-- sample_timestamp: timestamp (nullable = true)\n |-- timestamp_to_date: date (nullable = true)\n |-- add_timestamp1: timestamp (nullable = true)\n |-- add_timestamp2: date (nullable = true)\n |-- add_months: timestamp (nullable = true)\n |-- timestamp_diff_in_days: double (nullable = true)\n\nUsing SQL \n ********************\n+-----------------------+-----------------+-----------------------+--------------+-----------------------+----------------------+\n|sample_timestamp       |timestamp_to_date|add_timestamp1         |add_timestamp2|add_months             |timestamp_diff_in_days|\n+-----------------------+-----------------+-----------------------+--------------+-----------------------+----------------------+\n|2020-07-01 12:01:19.111|2020-07-01       |2020-07-01 12:01:29.111|2020-07-11    |2021-05-01 12:01:19.111|1277445.4833333334    |\n|2019-06-24 12:01:19.222|2019-06-24       |2019-06-24 12:01:29.222|2019-07-04    |2020-04-24 12:01:19.222|1814565.4833333334    |\n|2021-11-16 16:44:55.406|2021-11-16       |2021-11-16 16:45:05.406|2021-11-26    |2022-09-16 16:44:55.406|552841.8833333333     |\n+-----------------------+-----------------+-----------------------+--------------+-----------------------+----------------------+\n\nroot\n |-- sample_timestamp: timestamp (nullable = true)\n |-- timestamp_to_date: date (nullable = true)\n |-- add_timestamp1: timestamp (nullable = true)\n |-- add_timestamp2: date (nullable = true)\n |-- add_months: timestamp (nullable = true)\n |-- timestamp_diff_in_days: double (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["'''\nFetch YEAR, MONTH, DAY...\nSUNDAY - 0 , SATURDAY - 7\n''' \nprint(\"Using Pyhton \\n\",\"*\"*20)\ndf.select(\"sample_timestamp\",\n          current_timestamp(),\n          hour(\"sample_timestamp\").alias(\"hours\"),\n          minute(\"sample_timestamp\").alias(\"minute\"),\n          second(\"sample_timestamp\").alias(\"seconds\"),\n          month(\"sample_timestamp\").alias(\"month\"),\n          year(\"sample_timestamp\").alias(\"year\"),\n          dayofweek(\"sample_timestamp\").alias(\"dat of week\"),\n          dayofmonth(\"sample_timestamp\").alias(\"date of month\"),\n          weekofyear(\"sample_timestamp\").alias(\"weak of year\"),\n          quarter(\"sample_timestamp\").alias(\"quarter\")        \n          ).show(truncate=0)\n\n\nprint(\"Using Pyhton \\n\",\"*\"*20)\n\nspark.sql(\"\"\" select sample_timestamp,\n                current_timestamp(),\n                hour(sample_timestamp) as hours,\n                minute(sample_timestamp) as minute,\n                second(sample_timestamp) as seconds,\n                month(sample_timestamp) as month,\n                year(sample_timestamp) as year1,\n                dayofweek(sample_timestamp) as dat_of_week,\n                dayofmonth(sample_timestamp) as date_of_month,\n                weekofyear(sample_timestamp) as weak_of_year,\n                quarter(sample_timestamp) as quarter\n               from date_testing;\n\"\"\").show(truncate=0)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"14a9fff8-ad99-4bb2-a48c-f2641e914dc5","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Using Pyhton \n ********************\n+-----------------------+-----------------------+-----+------+-------+-----+----+-----------+-------------+------------+-------+\n|sample_timestamp       |current_timestamp()    |hours|minute|seconds|month|year|dat of week|date of month|weak of year|quarter|\n+-----------------------+-----------------------+-----+------+-------+-----+----+-----------+-------------+------------+-------+\n|2020-07-01 12:01:19.111|2022-12-05 14:11:23.159|12   |1     |19     |7    |2020|4          |1            |27          |3      |\n|2019-06-24 12:01:19.222|2022-12-05 14:11:23.159|12   |1     |19     |6    |2019|2          |24           |26          |2      |\n|2021-11-16 16:44:55.406|2022-12-05 14:11:23.159|16   |44    |55     |11   |2021|3          |16           |46          |4      |\n+-----------------------+-----------------------+-----+------+-------+-----+----+-----------+-------------+------------+-------+\n\nUsing Pyhton \n ********************\n+-----------------------+-----------------------+-----+------+-------+-----+-----+-----------+-------------+------------+-------+\n|sample_timestamp       |current_timestamp()    |hours|minute|seconds|month|year1|dat_of_week|date_of_month|weak_of_year|quarter|\n+-----------------------+-----------------------+-----+------+-------+-----+-----+-----------+-------------+------------+-------+\n|2020-07-01 12:01:19.111|2022-12-05 14:11:23.506|12   |1     |19     |7    |2020 |4          |1            |27          |3      |\n|2019-06-24 12:01:19.222|2022-12-05 14:11:23.506|12   |1     |19     |6    |2019 |2          |24           |26          |2      |\n|2021-11-16 16:44:55.406|2022-12-05 14:11:23.506|16   |44    |55     |11   |2021 |3          |16           |46          |4      |\n+-----------------------+-----------------------+-----+------+-------+-----+-----+-----------+-------------+------------+-------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Using Pyhton \n ********************\n+-----------------------+-----------------------+-----+------+-------+-----+----+-----------+-------------+------------+-------+\n|sample_timestamp       |current_timestamp()    |hours|minute|seconds|month|year|dat of week|date of month|weak of year|quarter|\n+-----------------------+-----------------------+-----+------+-------+-----+----+-----------+-------------+------------+-------+\n|2020-07-01 12:01:19.111|2022-12-05 14:11:23.159|12   |1     |19     |7    |2020|4          |1            |27          |3      |\n|2019-06-24 12:01:19.222|2022-12-05 14:11:23.159|12   |1     |19     |6    |2019|2          |24           |26          |2      |\n|2021-11-16 16:44:55.406|2022-12-05 14:11:23.159|16   |44    |55     |11   |2021|3          |16           |46          |4      |\n+-----------------------+-----------------------+-----+------+-------+-----+----+-----------+-------------+------------+-------+\n\nUsing Pyhton \n ********************\n+-----------------------+-----------------------+-----+------+-------+-----+-----+-----------+-------------+------------+-------+\n|sample_timestamp       |current_timestamp()    |hours|minute|seconds|month|year1|dat_of_week|date_of_month|weak_of_year|quarter|\n+-----------------------+-----------------------+-----+------+-------+-----+-----+-----------+-------------+------------+-------+\n|2020-07-01 12:01:19.111|2022-12-05 14:11:23.506|12   |1     |19     |7    |2020 |4          |1            |27          |3      |\n|2019-06-24 12:01:19.222|2022-12-05 14:11:23.506|12   |1     |19     |6    |2019 |2          |24           |26          |2      |\n|2021-11-16 16:44:55.406|2022-12-05 14:11:23.506|16   |44    |55     |11   |2021 |3          |16           |46          |4      |\n+-----------------------+-----------------------+-----+------+-------+-----+-----+-----------+-------------+------------+-------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Timestamp to Unix timestamp"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f3276aab-ea36-465e-9112-88d1d1cbd9cd","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["print(\"Using Pyhton \\n\",\"*\"*20)\ndf2=df.select('sample_timestamp',\n              unix_timestamp('sample_timestamp').alias(\"unix1\"),              \n              unix_timestamp('sample_timestamp',format=\"yyyy-MM-dd HH:mm:ss\").alias(\"unix2\"),\n              col('sample_timestamp').cast(\"long\").alias(\"unix3\")\n             )\ndf2.show(truncate=False)\ndf2.printSchema()\n\nprint(\"Using SQL \\n\",\"*\"*20)\ndf2=spark.sql(\"\"\"select sample_timestamp,\n                        unix_timestamp(sample_timestamp) as unix1,\n                        unix_timestamp(sample_timestamp,'yyyy-MM-dd HH:mm:ss') as unix2,\n                        to_unix_timestamp(sample_timestamp, 'yyyy-MM-dd HH:mm:ss') as unix3,\n                        to_unix_timestamp(sample_timestamp) as unix4,\n                        unix_timestamp(TIMESTAMP '2020-02-01 11:01:19.06') as unix5,                        \n                        cast(sample_timestamp as int) as unix6\n                 from date_testing;\"\"\")\ndf2.show(truncate=False)\ndf2.printSchema()\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d74644fd-945c-4b6c-9da5-a2c06b09f6ee","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Using Pyhton \n ********************\n+-----------------------+----------+----------+----------+\n|sample_timestamp       |unix1     |unix2     |unix3     |\n+-----------------------+----------+----------+----------+\n|2020-07-01 12:01:19.111|1593604879|1593604879|1593604879|\n|2019-06-24 12:01:19.222|1561377679|1561377679|1561377679|\n|2021-11-16 16:44:55.406|1637081095|1637081095|1637081095|\n+-----------------------+----------+----------+----------+\n\nroot\n |-- sample_timestamp: timestamp (nullable = true)\n |-- unix1: long (nullable = true)\n |-- unix2: long (nullable = true)\n |-- unix3: long (nullable = true)\n\nUsing SQL \n ********************\n+-----------------------+----------+----------+----------+----------+----------+----------+\n|sample_timestamp       |unix1     |unix2     |unix3     |unix4     |unix5     |unix6     |\n+-----------------------+----------+----------+----------+----------+----------+----------+\n|2020-07-01 12:01:19.111|1593604879|1593604879|1593604879|1593604879|1580554879|1593604879|\n|2019-06-24 12:01:19.222|1561377679|1561377679|1561377679|1561377679|1580554879|1561377679|\n|2021-11-16 16:44:55.406|1637081095|1637081095|1637081095|1637081095|1580554879|1637081095|\n+-----------------------+----------+----------+----------+----------+----------+----------+\n\nroot\n |-- sample_timestamp: timestamp (nullable = true)\n |-- unix1: long (nullable = true)\n |-- unix2: long (nullable = true)\n |-- unix3: long (nullable = true)\n |-- unix4: long (nullable = true)\n |-- unix5: long (nullable = true)\n |-- unix6: integer (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Using Pyhton \n ********************\n+-----------------------+----------+----------+----------+\n|sample_timestamp       |unix1     |unix2     |unix3     |\n+-----------------------+----------+----------+----------+\n|2020-07-01 12:01:19.111|1593604879|1593604879|1593604879|\n|2019-06-24 12:01:19.222|1561377679|1561377679|1561377679|\n|2021-11-16 16:44:55.406|1637081095|1637081095|1637081095|\n+-----------------------+----------+----------+----------+\n\nroot\n |-- sample_timestamp: timestamp (nullable = true)\n |-- unix1: long (nullable = true)\n |-- unix2: long (nullable = true)\n |-- unix3: long (nullable = true)\n\nUsing SQL \n ********************\n+-----------------------+----------+----------+----------+----------+----------+----------+\n|sample_timestamp       |unix1     |unix2     |unix3     |unix4     |unix5     |unix6     |\n+-----------------------+----------+----------+----------+----------+----------+----------+\n|2020-07-01 12:01:19.111|1593604879|1593604879|1593604879|1593604879|1580554879|1593604879|\n|2019-06-24 12:01:19.222|1561377679|1561377679|1561377679|1561377679|1580554879|1561377679|\n|2021-11-16 16:44:55.406|1637081095|1637081095|1637081095|1637081095|1580554879|1637081095|\n+-----------------------+----------+----------+----------+----------+----------+----------+\n\nroot\n |-- sample_timestamp: timestamp (nullable = true)\n |-- unix1: long (nullable = true)\n |-- unix2: long (nullable = true)\n |-- unix3: long (nullable = true)\n |-- unix4: long (nullable = true)\n |-- unix5: long (nullable = true)\n |-- unix6: integer (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Date to Unix timestamp"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"677a89ba-4b67-4181-be56-97657b57a262","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["print(\"Using Pyhton \\n\",\"*\"*20)\ndf2=df.select('sample_date',\n              unix_timestamp('sample_date').alias(\"unix1\"),              \n              unix_timestamp('sample_date',format=\"yyyy-MM-dd HH:mm:ss\").alias(\"unix2\"),\n              col('sample_date').cast(\"long\").alias(\"unix3\")\n             )\ndf2.show(truncate=False)\ndf2.printSchema()\n\nprint(\"Using SQL \\n\",\"*\"*20)\ndf2=spark.sql(\"\"\"select sample_date,\n                        unix_timestamp(sample_date) as unix1,\n                        unix_timestamp(sample_date,'yyyy-MM-dd HH:mm:ss') as unix2,\n                        to_unix_timestamp(sample_date, 'yyyy-MM-dd HH:mm:ss') as unix3,\n                        to_unix_timestamp(sample_date) as unix4,\n                        unix_timestamp(TIMESTAMP '2020-02-01 11:01:19.06') as unix5,                        \n                        cast(sample_date as int) as unix6\n                 from date_testing;\"\"\")\ndf2.show(truncate=False)\ndf2.printSchema()\n\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2558c343-e120-468b-b407-3af7b1da2229","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Using Pyhton \n ********************\n+-----------+----------+----------+-----+\n|sample_date|unix1     |unix2     |unix3|\n+-----------+----------+----------+-----+\n|2020-01-11 |1578700800|1578700800|null |\n|2019-05-21 |1558396800|1558396800|null |\n|2021-11-19 |1637280000|1637280000|null |\n+-----------+----------+----------+-----+\n\nroot\n |-- sample_date: date (nullable = true)\n |-- unix1: long (nullable = true)\n |-- unix2: long (nullable = true)\n |-- unix3: long (nullable = true)\n\nUsing SQL \n ********************\n+-----------+----------+----------+----------+----------+----------+-----+\n|sample_date|unix1     |unix2     |unix3     |unix4     |unix5     |unix6|\n+-----------+----------+----------+----------+----------+----------+-----+\n|2020-01-11 |1578700800|1578700800|1578700800|1578700800|1580554879|null |\n|2019-05-21 |1558396800|1558396800|1558396800|1558396800|1580554879|null |\n|2021-11-19 |1637280000|1637280000|1637280000|1637280000|1580554879|null |\n+-----------+----------+----------+----------+----------+----------+-----+\n\nroot\n |-- sample_date: date (nullable = true)\n |-- unix1: long (nullable = true)\n |-- unix2: long (nullable = true)\n |-- unix3: long (nullable = true)\n |-- unix4: long (nullable = true)\n |-- unix5: long (nullable = true)\n |-- unix6: integer (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Using Pyhton \n ********************\n+-----------+----------+----------+-----+\n|sample_date|unix1     |unix2     |unix3|\n+-----------+----------+----------+-----+\n|2020-01-11 |1578700800|1578700800|null |\n|2019-05-21 |1558396800|1558396800|null |\n|2021-11-19 |1637280000|1637280000|null |\n+-----------+----------+----------+-----+\n\nroot\n |-- sample_date: date (nullable = true)\n |-- unix1: long (nullable = true)\n |-- unix2: long (nullable = true)\n |-- unix3: long (nullable = true)\n\nUsing SQL \n ********************\n+-----------+----------+----------+----------+----------+----------+-----+\n|sample_date|unix1     |unix2     |unix3     |unix4     |unix5     |unix6|\n+-----------+----------+----------+----------+----------+----------+-----+\n|2020-01-11 |1578700800|1578700800|1578700800|1578700800|1580554879|null |\n|2019-05-21 |1558396800|1558396800|1558396800|1558396800|1580554879|null |\n|2021-11-19 |1637280000|1637280000|1637280000|1637280000|1580554879|null |\n+-----------+----------+----------+----------+----------+----------+-----+\n\nroot\n |-- sample_date: date (nullable = true)\n |-- unix1: long (nullable = true)\n |-- unix2: long (nullable = true)\n |-- unix3: long (nullable = true)\n |-- unix4: long (nullable = true)\n |-- unix5: long (nullable = true)\n |-- unix6: integer (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Unix timestamp to timestamp"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ee25842f-a6cb-457a-8bc0-c163455604cd","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["print(\"Using Pyhton \\n\",\"*\"*20)\ndf2=df.withColumn(\"unix_timestamp\",unix_timestamp('sample_timestamp')) \\\n      .withColumn(\"unix_date\",unix_timestamp('sample_date')) \\\n      .select('sample_timestamp', 'unix_timestamp',             \n              from_unixtime(\"unix_timestamp\").alias(\"back_to_timestamp\"),\n              'sample_date', 'unix_date',\n              from_unixtime(\"unix_date\").alias(\"back_to_date\")\n             )\ndf2.show(truncate=False)\ndf2.printSchema()\n\nprint(\"Using SQL \\n\",\"*\"*20)\ndf2=spark.sql(\"\"\"select sample_timestamp,unix_timestamp_val,\n                        from_unixtime(unix_timestamp_val) as back_to_timestamp,\n                        sample_date,unix_date,\n                        from_unixtime(unix_date) as back_to_date\n                  from \n                      (\n                        select sample_timestamp,sample_date,\n                        unix_timestamp(sample_timestamp) as unix_timestamp_val ,\n                         unix_timestamp(sample_date) as unix_date\n                        from date_testing\n                      )\n                        \"\"\")\ndf2.show(truncate=False)\ndf2.printSchema()\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c08774bc-6e89-446d-9d80-b66e5bf6a4bd","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Using Pyhton \n ********************\n+-----------------------+--------------+-------------------+-----------+----------+-------------------+\n|sample_timestamp       |unix_timestamp|back_to_timestamp  |sample_date|unix_date |back_to_date       |\n+-----------------------+--------------+-------------------+-----------+----------+-------------------+\n|2020-07-01 12:01:19.111|1593604879    |2020-07-01 12:01:19|2020-01-11 |1578700800|2020-01-11 00:00:00|\n|2019-06-24 12:01:19.222|1561377679    |2019-06-24 12:01:19|2019-05-21 |1558396800|2019-05-21 00:00:00|\n|2021-11-16 16:44:55.406|1637081095    |2021-11-16 16:44:55|2021-11-19 |1637280000|2021-11-19 00:00:00|\n+-----------------------+--------------+-------------------+-----------+----------+-------------------+\n\nroot\n |-- sample_timestamp: timestamp (nullable = true)\n |-- unix_timestamp: long (nullable = true)\n |-- back_to_timestamp: string (nullable = true)\n |-- sample_date: date (nullable = true)\n |-- unix_date: long (nullable = true)\n |-- back_to_date: string (nullable = true)\n\nUsing SQL \n ********************\n+-----------------------+------------------+-------------------+-----------+----------+-------------------+\n|sample_timestamp       |unix_timestamp_val|back_to_timestamp  |sample_date|unix_date |back_to_date       |\n+-----------------------+------------------+-------------------+-----------+----------+-------------------+\n|2020-07-01 12:01:19.111|1593604879        |2020-07-01 12:01:19|2020-01-11 |1578700800|2020-01-11 00:00:00|\n|2019-06-24 12:01:19.222|1561377679        |2019-06-24 12:01:19|2019-05-21 |1558396800|2019-05-21 00:00:00|\n|2021-11-16 16:44:55.406|1637081095        |2021-11-16 16:44:55|2021-11-19 |1637280000|2021-11-19 00:00:00|\n+-----------------------+------------------+-------------------+-----------+----------+-------------------+\n\nroot\n |-- sample_timestamp: timestamp (nullable = true)\n |-- unix_timestamp_val: long (nullable = true)\n |-- back_to_timestamp: string (nullable = true)\n |-- sample_date: date (nullable = true)\n |-- unix_date: long (nullable = true)\n |-- back_to_date: string (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Using Pyhton \n ********************\n+-----------------------+--------------+-------------------+-----------+----------+-------------------+\n|sample_timestamp       |unix_timestamp|back_to_timestamp  |sample_date|unix_date |back_to_date       |\n+-----------------------+--------------+-------------------+-----------+----------+-------------------+\n|2020-07-01 12:01:19.111|1593604879    |2020-07-01 12:01:19|2020-01-11 |1578700800|2020-01-11 00:00:00|\n|2019-06-24 12:01:19.222|1561377679    |2019-06-24 12:01:19|2019-05-21 |1558396800|2019-05-21 00:00:00|\n|2021-11-16 16:44:55.406|1637081095    |2021-11-16 16:44:55|2021-11-19 |1637280000|2021-11-19 00:00:00|\n+-----------------------+--------------+-------------------+-----------+----------+-------------------+\n\nroot\n |-- sample_timestamp: timestamp (nullable = true)\n |-- unix_timestamp: long (nullable = true)\n |-- back_to_timestamp: string (nullable = true)\n |-- sample_date: date (nullable = true)\n |-- unix_date: long (nullable = true)\n |-- back_to_date: string (nullable = true)\n\nUsing SQL \n ********************\n+-----------------------+------------------+-------------------+-----------+----------+-------------------+\n|sample_timestamp       |unix_timestamp_val|back_to_timestamp  |sample_date|unix_date |back_to_date       |\n+-----------------------+------------------+-------------------+-----------+----------+-------------------+\n|2020-07-01 12:01:19.111|1593604879        |2020-07-01 12:01:19|2020-01-11 |1578700800|2020-01-11 00:00:00|\n|2019-06-24 12:01:19.222|1561377679        |2019-06-24 12:01:19|2019-05-21 |1558396800|2019-05-21 00:00:00|\n|2021-11-16 16:44:55.406|1637081095        |2021-11-16 16:44:55|2021-11-19 |1637280000|2021-11-19 00:00:00|\n+-----------------------+------------------+-------------------+-----------+----------+-------------------+\n\nroot\n |-- sample_timestamp: timestamp (nullable = true)\n |-- unix_timestamp_val: long (nullable = true)\n |-- back_to_timestamp: string (nullable = true)\n |-- sample_date: date (nullable = true)\n |-- unix_date: long (nullable = true)\n |-- back_to_date: string (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3348f1ad-b834-4b98-867b-de3b08e45b43","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df.select(from_unixtime(lit(-2209095000000/1000)),unix_timestamp(to_date(lit(\"1780-02-02\")))).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"cc3e3dfc-8d59-4afc-a380-0c6f52a82b67","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-----------------------------------------------+--------------------------------------------------------+\n|from_unixtime(-2.209095E9, yyyy-MM-dd HH:mm:ss)|unix_timestamp(to_date(1780-02-02), yyyy-MM-dd HH:mm:ss)|\n+-----------------------------------------------+--------------------------------------------------------+\n|                            1899-12-30 18:30:00|                                             -5993049600|\n|                            1899-12-30 18:30:00|                                             -5993049600|\n|                            1899-12-30 18:30:00|                                             -5993049600|\n+-----------------------------------------------+--------------------------------------------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------------------------------------------+--------------------------------------------------------+\n|from_unixtime(-2.209095E9, yyyy-MM-dd HH:mm:ss)|unix_timestamp(to_date(1780-02-02), yyyy-MM-dd HH:mm:ss)|\n+-----------------------------------------------+--------------------------------------------------------+\n|                            1899-12-30 18:30:00|                                             -5993049600|\n|                            1899-12-30 18:30:00|                                             -5993049600|\n|                            1899-12-30 18:30:00|                                             -5993049600|\n+-----------------------------------------------+--------------------------------------------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0bab5dfc-ebea-4822-8619-fdcd503b7a28","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Date - TimeStamp functions","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3513366354034597}},"nbformat":4,"nbformat_minor":0}
